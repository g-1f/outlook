{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "class AnalysisSection(BaseModel):\n",
    "    \"\"\"Model for each analysis section\"\"\"\n",
    "    key_points: List[str]\n",
    "    summary: str\n",
    "\n",
    "class AnalysisOutput(BaseModel):\n",
    "    \"\"\"Model for structured analysis output\"\"\"\n",
    "    Revenue: Optional[AnalysisSection] = None\n",
    "    Margins_and_Cashflow: Optional[AnalysisSection] = None\n",
    "    Guidance: Optional[AnalysisSection] = None\n",
    "    Capital_Allocation: Optional[AnalysisSection] = None\n",
    "    MA: Optional[AnalysisSection] = None\n",
    "    Inventory_and_Pricing_Strategy: Optional[AnalysisSection] = None\n",
    "    Macro_Environment: Optional[AnalysisSection] = None\n",
    "    Products_and_RD: Optional[AnalysisSection] = None\n",
    "    confidence: float = Field(..., ge=0, le=1)\n",
    "\n",
    "    class Config:\n",
    "        allow_population_by_field_name = True\n",
    "\n",
    "async def execute_prompts(self, prompts: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"Execute prompts and return structured analysis\"\"\"\n",
    "    responses = []\n",
    "    \n",
    "    for prompt in prompts:\n",
    "        try:\n",
    "            # Format the prompt to request structured output\n",
    "            formatted_prompt = f\"\"\"\n",
    "            Analyze the following aspects and provide a structured response with key points and summary.\n",
    "            Each section should have:\n",
    "            - A list of key points (up to 7 bullet points)\n",
    "            - A brief summary\n",
    "            \n",
    "            {prompt[\"prompt\"]}\n",
    "            \"\"\"\n",
    "            \n",
    "            response = JsonFormer(\n",
    "                schema=AnalysisOutput,\n",
    "                llm=self.llm\n",
    "            ).invoke(formatted_prompt)\n",
    "            \n",
    "            # Convert pydantic model to dict and add metadata\n",
    "            analysis_dict = response.dict()\n",
    "            responses.append({\n",
    "                \"result\": analysis_dict,\n",
    "                \"type\": prompt[\"type\"],\n",
    "                \"heading\": prompt.get(\"heading\", \"\"),\n",
    "                \"confidence\": response.confidence,\n",
    "                \"bucket\": prompt.get(\"bucket\", 0)\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error executing prompt: {e}\")\n",
    "            \n",
    "    return responses\n",
    "\n",
    "def _format_bucket_prompt(self, bucket: List[tuple], ect: str, html_prompt: str) -> str:\n",
    "    \"\"\"Format prompt for structured output\"\"\"\n",
    "    metric_count = len(bucket)\n",
    "    prompt = [\n",
    "        f\"Answer the following {metric_count} questions using content from the Earnings call text.\",\n",
    "        \"For each section provide:\",\n",
    "        \"- Key points (up to 7 bullet points)\",\n",
    "        \"- A brief summary\\n\"\n",
    "    ]\n",
    "    \n",
    "    for i, (heading, metrics) in enumerate(bucket, 1):\n",
    "        metrics_str = \", \".join(metrics)\n",
    "        prompt.append(\n",
    "            f\"{i}. Analyze the {metrics_str} of the company under the heading: {heading}\"\n",
    "        )\n",
    "    \n",
    "    prompt.append(f\"\\nEarnings call text:\\n{ect}\")\n",
    "    \n",
    "    return \"\\n\".join(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, List, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "class ECTAnalyzer:\n",
    "    # ... other methods remain the same ...\n",
    "\n",
    "    async def get_ect_summary(self, company_id: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Get ECT summary for a company.\n",
    "        Returns a list containing the analysis or error message.\n",
    "        \"\"\"\n",
    "        # Get documents\n",
    "        documents_metadata = await self.get_earnings_by_company_id(company_id)\n",
    "        if not documents_metadata:\n",
    "            return [{\"error\": \"No earnings document related to query is found\"}]\n",
    "            \n",
    "        # Sort by date to get latest document\n",
    "        documents_metadata.sort(\n",
    "            key=lambda x: datetime.strptime(x.document_date_s, \"%Y-%m-%d\"),\n",
    "            reverse=True\n",
    "        )\n",
    "        latest_doc = documents_metadata[0]\n",
    "        \n",
    "        # Get ECT content\n",
    "        content = await self.get_earnings_content(latest_doc)\n",
    "        if not content:\n",
    "            return [{\"error\": \"Could not fetch earnings content\"}]\n",
    "            \n",
    "        # Generate and execute analysis prompts\n",
    "        prompts = self.generate_ect_prompts(\n",
    "            ect=content,\n",
    "            id_bb_company=company_id,\n",
    "            html_prompt=\"\"  # Can be parameterized if needed\n",
    "        )\n",
    "        \n",
    "        # Execute prompts and get structured analysis\n",
    "        responses = await self.execute_prompts(prompts)\n",
    "        \n",
    "        # Process responses into final format\n",
    "        analysis_sections = {}\n",
    "        for response in responses:\n",
    "            if response[\"confidence\"] > 0.7:  # Confidence threshold\n",
    "                # Each response now contains structured analysis sections\n",
    "                analysis_dict = response[\"result\"]\n",
    "                analysis_sections.update(analysis_dict)\n",
    "                \n",
    "        # Return final structured response\n",
    "        return [{\n",
    "            \"metadata\": {\n",
    "                \"company\": latest_doc.company_s,\n",
    "                \"period\": f\"Q{latest_doc.quarter_s} {latest_doc.year_s}\",\n",
    "                \"date\": latest_doc.document_date_s,\n",
    "                \"ticker\": latest_doc.tickers_s[0] if latest_doc.tickers_s else None\n",
    "            },\n",
    "            \"analysis\": analysis_sections\n",
    "        }]\n",
    "\n",
    "# Usage example:\n",
    "async def main():\n",
    "    analyzer = ECTAnalyzer(gssso_token=gs_auth.get_gssso())\n",
    "    result = await analyzer.get_ect_summary(\"107357\")  # Example for Apple\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
