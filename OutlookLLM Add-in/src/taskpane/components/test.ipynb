{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration main-f9306ececa7c2eca\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/main to /Users/gyf/.cache/huggingface/datasets/openai___parquet/main-f9306ececa7c2eca/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfaa2aed44324a83ad0df221bc94e3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fadd1218a84e63974c1614c1e46ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b1ebd2e3d3417b82e2b1712924444b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd49bffcb842492696eabe60c389b1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /Users/gyf/.cache/huggingface/datasets/openai___parquet/main-f9306ececa7c2eca/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08eee4d7c8e64550b8166c1a499efa33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2af3ef47094f0993deb488385a67dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14946 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "import logging\n",
    "from typing import Tuple, List, Optional\n",
    "from dataclasses import dataclass\n",
    "from contextlib import contextmanager\n",
    "import pdfplumber\n",
    "from PyPDF2 import PdfReader\n",
    "import base64\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "@dataclass\n",
    "class FileProcessingResult:\n",
    "    encoded_files: List[str]\n",
    "    file_contents: List[str]\n",
    "    file_names: List[str]\n",
    "    error: Optional[str] = None\n",
    "\n",
    "class FileSizeError(Exception):\n",
    "    pass\n",
    "\n",
    "class FileTypeError(Exception):\n",
    "    pass\n",
    "\n",
    "class PDFProcessor:\n",
    "    MAX_FILE_SIZE_MB = 10\n",
    "    SUPPORTED_TYPES = ['pdf', 'txt']\n",
    "    \n",
    "    @staticmethod\n",
    "    def validate_file_size(content: bytes) -> None:\n",
    "        size_mb = len(content) / (1024 * 1024)\n",
    "        if size_mb > PDFProcessor.MAX_FILE_SIZE_MB:\n",
    "            raise FileSizeError(f\"File size {size_mb:.1f}MB exceeds limit of {PDFProcessor.MAX_FILE_SIZE_MB}MB\")\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_file_type(filename: str) -> None:\n",
    "        ext = filename.lower().split('.')[-1]\n",
    "        if ext not in PDFProcessor.SUPPORTED_TYPES:\n",
    "            raise FileTypeError(f\"Unsupported file type: {ext}\")\n",
    "\n",
    "    @contextmanager\n",
    "    def safe_pdf_processing(self, content: bytes):\n",
    "        pdf_file = io.BytesIO(content)\n",
    "        try:\n",
    "            yield pdf_file\n",
    "        finally:\n",
    "            pdf_file.close()\n",
    "\n",
    "    def process_pdf(self, content: bytes) -> str:\n",
    "        with self.safe_pdf_processing(content) as pdf_file:\n",
    "            text_content = []\n",
    "            \n",
    "            # Try with pdfplumber first\n",
    "            try:\n",
    "                with pdfplumber.open(pdf_file) as pdf:\n",
    "                    for page in pdf.pages:\n",
    "                        extracted_text = page.extract_text()\n",
    "                        if extracted_text:\n",
    "                            text_content.append(extracted_text)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"pdfplumber extraction failed: {e}, trying PyPDF2\")\n",
    "                \n",
    "                # Fallback to PyPDF2\n",
    "                pdf_file.seek(0)  # Reset file pointer\n",
    "                try:\n",
    "                    reader = PdfReader(pdf_file)\n",
    "                    for page in reader.pages:\n",
    "                        text = page.extract_text()\n",
    "                        if text:\n",
    "                            text_content.append(text)\n",
    "                except Exception as e:\n",
    "                    raise Exception(f\"Both PDF extraction methods failed: {e}\")\n",
    "\n",
    "        return '\\n'.join(text_content)\n",
    "\n",
    "def process_files(contents: List[str], filenames: List[str]) -> FileProcessingResult:\n",
    "    \"\"\"\n",
    "    Process multiple files and return encoded results\n",
    "    \"\"\"\n",
    "    if not contents or not filenames:\n",
    "        return FileProcessingResult([], [], [])\n",
    "\n",
    "    processor = PDFProcessor()\n",
    "    encoded_files = []\n",
    "    file_contents = []\n",
    "    processed_names = []\n",
    "\n",
    "    for content_str, filename in zip(contents, filenames):\n",
    "        try:\n",
    "            # Validate and decode base64 content\n",
    "            try:\n",
    "                content_type, content_string = content_str.split(',')\n",
    "                decoded = base64.b64decode(content_string)\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Invalid base64 content: {e}\")\n",
    "\n",
    "            # Validate file\n",
    "            processor.validate_file_type(filename)\n",
    "            processor.validate_file_size(decoded)\n",
    "\n",
    "            if filename.lower().endswith('.pdf'):\n",
    "                # Process PDF\n",
    "                text_content = processor.process_pdf(decoded)\n",
    "                \n",
    "                # Re-encode processed content\n",
    "                encoded = base64.b64encode(decoded).decode()\n",
    "                encoded_files.append(f'data:application/pdf;base64,{encoded}')\n",
    "                file_contents.append(text_content)\n",
    "                processed_names.append(filename)\n",
    "                \n",
    "            elif filename.lower().endswith('.txt'):\n",
    "                # Process text files\n",
    "                text_content = decoded.decode('utf-8')\n",
    "                encoded_files.append(f'data:text/plain;charset=utf-8,{content_str}')\n",
    "                file_contents.append(text_content)\n",
    "                processed_names.append(filename)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing file {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return FileProcessingResult(\n",
    "        encoded_files=encoded_files,\n",
    "        file_contents=file_contents,\n",
    "        file_names=processed_names\n",
    "    )\n",
    "\n",
    "def register_file_upload_callback(app, name):\n",
    "    @app.callback(\n",
    "        Output(f'uploaded-file-{name}', component_property='data'),\n",
    "        Input(f'upload-data-{name}', component_property='contents'),\n",
    "        State(f'upload-data-{name}', component_property='filename'),\n",
    "    )\n",
    "    def upload_files(contents, filenames):\n",
    "        if not contents:\n",
    "            return [], [], []\n",
    "            \n",
    "        if not isinstance(contents, list):\n",
    "            contents = [contents]\n",
    "            filenames = [filenames]\n",
    "\n",
    "        result = process_files(contents, filenames)\n",
    "        return result.encoded_files, result.file_contents, result.file_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
