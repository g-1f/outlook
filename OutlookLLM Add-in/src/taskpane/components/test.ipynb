{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, List, Optional, Any\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from goldmansachs.awm_genai import ConverseAILangchainLLM, JsonFormer\n",
    "\n",
    "class EarningsMetadata(BaseModel):\n",
    "    quarter_s: str\n",
    "    year_s: str\n",
    "    company_s: str\n",
    "    doc_type_s: str\n",
    "    tags_s: List[str]\n",
    "    event_time_s: str\n",
    "    companyId_s: str\n",
    "    tickers_s: List[str]\n",
    "    cusips_s: List[str]\n",
    "    isins_s: List[str]\n",
    "    sedols_s: List[str]\n",
    "    document_date_s: str\n",
    "    objecturl: Optional[str] = None\n",
    "\n",
    "class ECTConfig:\n",
    "    HEADINGS = {\n",
    "        \"Revenue\": [\"company wide revenue\", \"segment-wise revenue\", \"revenue drivers\"],\n",
    "        \"Margins and Cashflow\": [\"margins\", \"cash drivers\"],\n",
    "        \"Guidance\": [\"Playbook\", \"Guidance\", \"projection\"],\n",
    "        \"Capital Allocation\": [\"capital allocation\", \"capex\", \"share repurchase\"],\n",
    "        \"M&A\": [\"M&A\", \"merger acquisitions\"],\n",
    "        \"Inventory & Pricing Strategy\": [\"inventory\", \"pricing strategy\"],\n",
    "        \"Macro Environment\": [\"Macro Environment\", \"Labor\", \"Supply Chain\"],\n",
    "        \"Products & R&D\": [\"product development\", \"Product lines\", \"new products\", \"R&D\"]\n",
    "    }\n",
    "\n",
    "class ECTAnalyzer:\n",
    "    def __init__(self, gssso_token: str):\n",
    "        self.gssso_token = gssso_token\n",
    "        self.llm = ConverseAILangchainLLM.from_defaults('fluentai', model_name='gpt-4o')\n",
    "        \n",
    "    async def get_earnings_documents(self, company_id: str) -> List[EarningsMetadata]:\n",
    "        query = f\"metadata_txt:{company_id}\"\n",
    "        headers = {\n",
    "            \"Cookie\": f\"GSSSO={self.gssso_token}\",\n",
    "            \"responseType\": \"application/json\"\n",
    "        }\n",
    "        base_url = \"https://vip.gsam.prod.search.lex.site.gs.com/searchService/rest/search/bulk/query/table:com.gs.swm.gena1\"\n",
    "        full_url = f\"{base_url}?%20AND%20({query})\"\n",
    "        \n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            retry = 0\n",
    "            while retry < 5:\n",
    "                try:\n",
    "                    async with session.get(full_url, headers=headers) as response:\n",
    "                        if response.status != 200:\n",
    "                            retry += 1\n",
    "                            await asyncio.sleep(1)\n",
    "                            continue\n",
    "                            \n",
    "                        content = await response.text()\n",
    "                        soup = BeautifulSoup(content, 'lxml')\n",
    "                        documents = []\n",
    "                        \n",
    "                        for doc in soup.find_all(\"lexDocument\"):\n",
    "                            try:\n",
    "                                metadata_field = doc.find('field', {'name': 'metadata_txt'})\n",
    "                                if metadata_field:\n",
    "                                    metadata_txt = metadata_field.find('values').text.strip()\n",
    "                                    metadata = EarningsMetadata(**json.loads(metadata_txt))\n",
    "                                    documents.append(metadata)\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error parsing document metadata: {e}\")\n",
    "                                \n",
    "                        return documents\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Request error: {e}\")\n",
    "                    retry += 1\n",
    "                    await asyncio.sleep(1)\n",
    "                    \n",
    "        return []\n",
    "\n",
    "    async def get_earnings_content(self, metadata: EarningsMetadata) -> str:\n",
    "        if not metadata.objecturl:\n",
    "            return \"\"\n",
    "            \n",
    "        headers = {\"Cookie\": f\"GSSSO={self.gssso_token}\"}\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            try:\n",
    "                async with session.get(metadata.objecturl, headers=headers) as response:\n",
    "                    if response.status == 200:\n",
    "                        return await response.text()\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching content: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    def generate_ect_prompts(self, ect: str, company_id: str, html_prompt: str = \"\") -> List[Dict]:\n",
    "        items = list(ECTConfig.HEADINGS.items())\n",
    "        bucket_size = 4\n",
    "        prompt_buckets = [items[i:i + bucket_size] for i in range(0, len(items), bucket_size)]\n",
    "        \n",
    "        prompts = []\n",
    "        for bucket_id, bucket in enumerate(prompt_buckets):\n",
    "            prompt_str = self._format_bucket_prompt(bucket, ect, html_prompt)\n",
    "            prompts.append({\n",
    "                \"prompt\": prompt_str,\n",
    "                \"company\": company_id,\n",
    "                \"type\": \"ECT\",\n",
    "                \"bucket\": bucket_id,\n",
    "                \"model\": \"gpt-4o\"\n",
    "            })\n",
    "        return prompts\n",
    "\n",
    "    def _format_bucket_prompt(self, bucket: List[tuple], ect: str, html_prompt: str) -> str:\n",
    "        metric_count = len(bucket)\n",
    "        prompt = f\" Answer the following {metric_count} questions using content from the Earnings call text specified below. \"\n",
    "        prompt += \"Make sure to include all supporting information available in the text without repeating information.\\n\"\n",
    "        prompt += f\"Make sure the response is able to answer the {metric_count} questions below {html_prompt}\\n\"\n",
    "        \n",
    "        for i, (heading, metrics) in enumerate(bucket, 1):\n",
    "            metrics_str = \", \".join(metrics)\n",
    "            prompt += f\"{i}. How is the {metrics_str} of the company? \"\n",
    "            prompt += f\"Give an in-depth response under the sub-heading: {heading}. \"\n",
    "            prompt += \"Use up to 7 bullets to formulate the response.\\n\"\n",
    "            \n",
    "        prompt += f\"The Earnings call text is as follows: \\n{ect}\"\n",
    "        return prompt\n",
    "\n",
    "    async def execute_prompts(self, prompts: List[Dict]) -> List[Dict]:\n",
    "        class AnalysisOutput(BaseModel):\n",
    "            analysis: str = Field(..., description=\"Detailed analysis of the given aspect\")\n",
    "            confidence: float = Field(..., ge=0, le=1, description=\"Confidence score of the analysis\")\n",
    "\n",
    "        responses = []\n",
    "        for prompt in prompts:\n",
    "            try:\n",
    "                response = JsonFormer(\n",
    "                    schema=AnalysisOutput,\n",
    "                    llm=self.llm\n",
    "                ).invoke(prompt[\"prompt\"])\n",
    "                \n",
    "                responses.append({\n",
    "                    \"result\": response.analysis,\n",
    "                    \"type\": prompt[\"type\"],\n",
    "                    \"heading\": prompt.get(\"heading\", \"\"),\n",
    "                    \"confidence\": response.confidence,\n",
    "                    \"bucket\": prompt.get(\"bucket\", 0)\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error executing prompt: {e}\")\n",
    "\n",
    "        return responses\n",
    "\n",
    "    async def get_enhanced_ect(self, company_id: str) -> Dict:\n",
    "        documents = await self.get_earnings_documents(company_id)\n",
    "        if not documents:\n",
    "            return {\"error\": \"No earnings documents found\"}\n",
    "            \n",
    "        documents.sort(key=lambda x: x.document_date_s, reverse=True)\n",
    "        latest_doc = documents[0]\n",
    "        \n",
    "        content = await self.get_earnings_content(latest_doc)\n",
    "        if not content:\n",
    "            return {\"error\": \"Could not fetch earnings content\"}\n",
    "            \n",
    "        prompts = self.generate_ect_prompts(content, company_id)\n",
    "        responses = await self.execute_prompts(prompts)\n",
    "        \n",
    "        analysis_by_heading = {}\n",
    "        for response in responses:\n",
    "            if response[\"confidence\"] > 0.7:\n",
    "                analysis_by_heading[response[\"heading\"]] = response[\"result\"]\n",
    "        \n",
    "        return {\n",
    "            \"metadata\": {\n",
    "                \"company\": latest_doc.company_s,\n",
    "                \"period\": f\"Q{latest_doc.quarter_s} {latest_doc.year_s}\",\n",
    "                \"date\": latest_doc.document_date_s,\n",
    "                \"ticker\": latest_doc.tickers_s[0] if latest_doc.tickers_s else None\n",
    "            },\n",
    "            \"analysis\": analysis_by_heading\n",
    "        }\n",
    "\n",
    "async def main():\n",
    "    analyzer = ECTAnalyzer(gssso_token=\"your_token\")\n",
    "    result = await analyzer.get_enhanced_ect(\"107357\")  # Apple's company ID\n",
    "    print(json.dumps(result, indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
