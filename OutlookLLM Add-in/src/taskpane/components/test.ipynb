{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_earnings_by_company_id(self, company_id: str) -> List[EarningsMetadata]:\n",
    "    \"\"\"Fetch earnings documents from the database\"\"\"\n",
    "    query = f\"metadata_txt:{company_id}\"\n",
    "    headers = {\n",
    "        \"Cookie\": f\"GSSSO={self.gssso_token}\",\n",
    "        \"responseType\": \"application/json\"\n",
    "    }\n",
    "    base_url = \"https://vip.gsam.prod.search.lex.site.gs.com/searchService/rest/search/bulk/query/table:com.gs.swm.genai\"\n",
    "    full_url = f\"{base_url}%20AND%20({query})\"\n",
    "    \n",
    "    result = []\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        retry = 0\n",
    "        while retry < 5:\n",
    "            try:\n",
    "                async with session.get(full_url, headers=headers) as response:\n",
    "                    if response.status != 200:\n",
    "                        retry += 1\n",
    "                        await asyncio.sleep(1)\n",
    "                        continue\n",
    "                        \n",
    "                    content = await response.text()\n",
    "                    soup = BeautifulSoup(content, 'lxml')\n",
    "                    \n",
    "                    # Process each lexDocument\n",
    "                    for doc in soup.find_all(\"lexDocument\"):\n",
    "                        # First find metadata_txt field\n",
    "                        metadata_field = doc.find('field', {'name': 'metadata_txt'})\n",
    "                        if not metadata_field:\n",
    "                            continue\n",
    "                            \n",
    "                        try:\n",
    "                            # Get metadata JSON\n",
    "                            metadata_value = metadata_field.find('values').text.strip()\n",
    "                            metadata = json.loads(metadata_value)\n",
    "                            \n",
    "                            # Get objecturl if exists\n",
    "                            objecturl_field = doc.find('field', {'name': 'objecturl'})\n",
    "                            if objecturl_field:\n",
    "                                metadata['objecturl'] = objecturl_field.find('values').text.strip()\n",
    "                            \n",
    "                            # Create earnings metadata object\n",
    "                            earnings_metadata = EarningsMetadata(**metadata)\n",
    "                            result.append(earnings_metadata)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error parsing document: {e}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # If we got here, we successfully processed the response\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Request error: {e}\")\n",
    "                retry += 1\n",
    "                await asyncio.sleep(1)\n",
    "                \n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
