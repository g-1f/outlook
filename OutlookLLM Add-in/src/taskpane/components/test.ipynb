{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_file_upload_callback(app, name):\n",
    "    @app.callback(\n",
    "        Output('uploaded-file' + name, component_property='data'),\n",
    "        Input('upload-data' + name, component_property='contents'),\n",
    "        State('upload-data' + name, component_property='filename'),\n",
    "        State('uploaded-file' + name, component_property='data')\n",
    "    )\n",
    "    def upload_files(contents, filenames, current_data):\n",
    "        \"\"\"\n",
    "        This callback processes user-uploaded files (PDFs, TXTs). \n",
    "        It returns a tuple of:\n",
    "            (\n",
    "              encoded_files,  # A list of base64-encoded file contents (for display in an iframe, e.g.)\n",
    "              file_contents,  # A list of the textual extractions from those files\n",
    "              file_names      # A list of the actual filenames\n",
    "            )\n",
    "        \"\"\"\n",
    "\n",
    "        # If there's existing data, unpack it. Otherwise initialize.\n",
    "        encoded_files = current_data[0] if current_data else []\n",
    "        file_texts    = current_data[1] if current_data else []\n",
    "        file_names    = current_data[2] if current_data else []\n",
    "\n",
    "        if not contents:\n",
    "            return encoded_files, file_texts, file_names\n",
    "\n",
    "        # If a user uploads multiple files, contents/filenames are lists\n",
    "        for content, filename in zip(contents, filenames):\n",
    "            content_type, content_string = content.split(',')\n",
    "            try:\n",
    "                decoded = base64.b64decode(content_string)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error decoding base64 content for {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Process PDF file\n",
    "            if filename.lower().endswith('.pdf'):\n",
    "                logger.info(f\"STARTING PDF EXTRACTION: {filename}\")\n",
    "                text_from_pdf, pdf_data_encoded = process_pdf(decoded, max_size_mb=2.0)\n",
    "                # text_from_pdf: str (extracted text)\n",
    "                # pdf_data_encoded: str (base64-encoded PDF up to max_size_mb if applicable)\n",
    "\n",
    "                # Append the extracted text\n",
    "                file_texts.append(text_from_pdf if text_from_pdf else \"\")\n",
    "                # Store a 'data:application/pdf;base64,...' pointer for the (possibly truncated) PDF\n",
    "                encoded_files.append('data:application/pdf;base64,' + pdf_data_encoded)\n",
    "                file_names.append(filename)\n",
    "                logger.info(f\"FINISHED PDF EXTRACTION: {filename}\")\n",
    "\n",
    "            # Process TXT file\n",
    "            elif filename.lower().endswith('.txt'):\n",
    "                logger.info(f\"Reading plain text: {filename}\")\n",
    "                text_str = decoded.decode(errors='replace')\n",
    "                # Append the extracted text\n",
    "                file_texts.append(text_str)\n",
    "                # Store a 'data:text/plain;charset=utf-8,...'\n",
    "                encoded_files.append('data:text/plain;charset=utf-8,' + base64.b64encode(decoded).decode())\n",
    "                file_names.append(filename)\n",
    "\n",
    "            else:\n",
    "                logger.warning(f\"Unsupported file type: {filename}\")\n",
    "                continue\n",
    "\n",
    "        return encoded_files, file_texts, file_names\n",
    "\n",
    "\n",
    "def process_pdf(decoded_pdf: bytes, max_size_mb: float = 1.0) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Helper function to:\n",
    "    - Extract text from a PDF using pdfplumber (handling None-text cases).\n",
    "    - Possibly limit the PDF to a certain size in MB before encoding as base64\n",
    "      so you don't blow up your front-end by displaying a huge PDF.\n",
    "\n",
    "    Returns:\n",
    "      (extracted_text, base64_pdf_string)\n",
    "    \"\"\"\n",
    "    all_text = []\n",
    "    pdf_in_mem = io.BytesIO(decoded_pdf)\n",
    "\n",
    "    # --- Extract Text Safely Using pdfplumber ---\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_in_mem) as pdfplumb:\n",
    "            for page in pdfplumb.pages:\n",
    "                page_text = page.extract_text() or \"\"  # handle None returns\n",
    "                all_text.append(page_text)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"pdfplumber failed to read PDF: {e}\")\n",
    "        all_text.append(\"[Error reading PDF text via pdfplumber]\")\n",
    "\n",
    "    extracted_text = \"\\n\".join(all_text)\n",
    "\n",
    "    # --- Rewind the buffer so PyPDF2 can read it again if needed ---\n",
    "    pdf_in_mem.seek(0)\n",
    "\n",
    "    # --- Potentially limit PDF size for embedding ---\n",
    "    #    If you want the entire PDF, no matter how large, you can skip the chunking logic below.\n",
    "    try:\n",
    "        reader = PdfReader(pdf_in_mem)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"PyPDF2 failed to read PDF: {e}\")\n",
    "        # If PyPDF2 fails, we can fallback to returning the entire (original) PDF as base64\n",
    "        return extracted_text, base64.b64encode(decoded_pdf).decode()\n",
    "\n",
    "    writer = PdfWriter()\n",
    "    current_size_mb = 0.0\n",
    "    for i, page in enumerate(reader.pages):\n",
    "        writer.add_page(page)\n",
    "        temp_stream = io.BytesIO()\n",
    "        writer.write(temp_stream)\n",
    "        pdf_chunk = temp_stream.getvalue()\n",
    "        size_in_mb = len(pdf_chunk) / (1024 * 1024)\n",
    "        if size_in_mb <= max_size_mb:\n",
    "            # If still under the size limit, keep going\n",
    "            current_size_mb = size_in_mb\n",
    "        else:\n",
    "            # Remove the last page added if it exceeded the limit\n",
    "            # Alternatively, you can break here (keeping partial pages).\n",
    "            writer.pages.pop()\n",
    "            logger.warning(\n",
    "                f\"Max size reached at page {i}. Final embedded PDF size ~ {current_size_mb:.2f} MB.\"\n",
    "            )\n",
    "            break\n",
    "\n",
    "    # Now, write out the final truncated PDF\n",
    "    final_stream = io.BytesIO()\n",
    "    writer.write(final_stream)\n",
    "    final_pdf_bytes = final_stream.getvalue()\n",
    "\n",
    "    encoded_pdf = base64.b64encode(final_pdf_bytes).decode()\n",
    "    return extracted_text, encoded_pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
