{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_expanding_window_backtest(data, initial_train_size, trade_lag, feature_extractor=None, device='cuda'):\n",
    "    \"\"\"\n",
    "    Run expanding window backtest\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame containing features and target\n",
    "        initial_train_size: Initial training window size\n",
    "        trade_lag: Trading lag for signals\n",
    "        feature_extractor: Optional feature extractor\n",
    "        device: Computing device\n",
    "    \"\"\"\n",
    "    all_predictions = []\n",
    "    expanding_metrics = []\n",
    "    \n",
    "    # Get total length respecting trade_lag\n",
    "    total_length = len(data) - trade_lag\n",
    "    \n",
    "    # Start after initial training period\n",
    "    for t in range(initial_train_size, total_length):\n",
    "        print(f\"\\nWindow End: {data.index[t]}\")\n",
    "        \n",
    "        # Get training data up to time t\n",
    "        train_x = data[x_label_changes][:t]\n",
    "        train_y = data['y'][:t]\n",
    "        \n",
    "        # Convert to tensors\n",
    "        train_x = torch.tensor(train_x.values, dtype=torch.float64, device=device)\n",
    "        train_y = torch.tensor(train_y.values, dtype=torch.float64, device=device)\n",
    "        \n",
    "        # Initialize and train model\n",
    "        likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        model = GPRegressionModel(train_x, train_y, likelihood, feature_extractor)\n",
    "        model = model.to(device)\n",
    "        likelihood = likelihood.to(device)\n",
    "        \n",
    "        # Train model\n",
    "        model, likelihood, history = train_gpr_model(\n",
    "            model=model,\n",
    "            likelihood=likelihood,\n",
    "            train_x=train_x,\n",
    "            train_y=train_y,\n",
    "            device=device,\n",
    "            n_epochs=100  # Reduced epochs for backtest\n",
    "        )\n",
    "        \n",
    "        # Make prediction for next point\n",
    "        with torch.no_grad():\n",
    "            test_x = data[x_label_changes].iloc[t:t+1]\n",
    "            test_x = torch.tensor(test_x.values, dtype=torch.float64, device=device)\n",
    "            pred = model(test_x)\n",
    "            pred_mean = pred.mean.cpu().numpy()[0]\n",
    "        \n",
    "        # Store prediction\n",
    "        all_predictions.append({\n",
    "            'date': data.index[t + trade_lag],\n",
    "            'prediction': pred_mean,\n",
    "            'actual': data['y'].iloc[t + trade_lag],\n",
    "            'train_loss': history['loss'][-1]\n",
    "        })\n",
    "        \n",
    "        # Calculate expanding window metrics\n",
    "        if len(all_predictions) > 1:\n",
    "            preds_df = pd.DataFrame(all_predictions)\n",
    "            preds_df['returns'] = preds_df['prediction'] * preds_df['actual']\n",
    "            \n",
    "            # Calculate metrics\n",
    "            sharpe = np.sqrt(252) * preds_df['returns'].mean() / preds_df['returns'].std()\n",
    "            cum_return = (1 + preds_df['returns']).cumprod().iloc[-1] - 1\n",
    "            \n",
    "            expanding_metrics.append({\n",
    "                'date': data.index[t + trade_lag],\n",
    "                'sharpe': sharpe,\n",
    "                'cum_return': cum_return,\n",
    "                'window_size': t\n",
    "            })\n",
    "    \n",
    "    # Convert results to DataFrames\n",
    "    predictions_df = pd.DataFrame(all_predictions)\n",
    "    metrics_df = pd.DataFrame(expanding_metrics)\n",
    "    \n",
    "    # Plot results\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 15))\n",
    "    \n",
    "    # Plot predictions vs actual\n",
    "    axes[0].plot(predictions_df['date'], predictions_df['prediction'], label='Predicted')\n",
    "    axes[0].plot(predictions_df['date'], predictions_df['actual'], label='Actual')\n",
    "    axes[0].set_title('Predictions vs Actual')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Plot cumulative returns\n",
    "    predictions_df['cum_returns'] = (1 + predictions_df['returns']).cumprod()\n",
    "    axes[1].plot(predictions_df['date'], predictions_df['cum_returns'])\n",
    "    axes[1].set_title('Cumulative Returns')\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # Plot expanding window metrics\n",
    "    axes[2].plot(metrics_df['date'], metrics_df['sharpe'], label='Rolling Sharpe')\n",
    "    axes[2].set_title('Expanding Window Sharpe Ratio')\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return predictions_df, metrics_df\n",
    "\n",
    "# Usage:\n",
    "\"\"\"\n",
    "initial_train_size = 252  # One year\n",
    "trade_lag = 21  # One month\n",
    "\n",
    "predictions, metrics = run_expanding_window_backtest(\n",
    "    data=data,\n",
    "    initial_train_size=initial_train_size,\n",
    "    trade_lag=trade_lag,\n",
    "    feature_extractor=feature_extractor,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Print final metrics\n",
    "print(\"\\nFinal Backtest Metrics:\")\n",
    "print(f\"Sharpe Ratio: {metrics['sharpe'].iloc[-1]:.2f}\")\n",
    "print(f\"Total Return: {(metrics['cum_return'].iloc[-1]*100):.2f}%\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
